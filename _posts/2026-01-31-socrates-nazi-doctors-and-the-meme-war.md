---
id: 1511
title: Socrates, Nazi Doctors, and the Meme War
date: 2026-01-30
author: tsykoduk
layout: post
guid: https://greg.nokes.name/?p=1520
permalink: /2026/01/30/socrates-nazi-doctors-and-the-meme-war/
categories:
  - Philosophy
excerpt_separator: <!--more-->
description: "Exploring whether education and intelligence protect against evil, from Nazi doctors to AI-enabled disinformation, and what we can actually do about it."
---

<div style="float: right; padding: 10px 10px 10px 10px;"><img src="/binaries/2026/01/BalancingAct.png" width="150" alt="A solitary figure walks a tightrope suspended between an ancient Greek marble column and a towering wall of glowing digital screens filled with fragmented text and imagery. Far below, a swirling red-orange chasm suggests chaos. The figure carries a small lantern that casts warm golden light, contrasting with the cool blues and grays of the atmospheric, painterly scene."><br />
<sub><i>Image by <a href="https://ChatGPT.com">ChatGPT</a></i></sub></div>

It increasingly feels like we are walking a tightrope stretched between ancient wisdom and algorithmic chaos, the ground beneath us less stable than we'd like to admit.

Socrates believed that no one does evil willingly. Evil, in his view, stems from ignorance - if people truly understood what was good, they would choose it. The implication is hopeful: educate people, cultivate their intelligence, and you inoculate them against evil.

It's a comforting thought. It's also empirically testable.

I recently found myself in a conversation exploring whether this premise holds water. What I found was more troubling - and more interesting - than I expected.

<!--more-->

## The Numbers (At First Glance)

There is, in fact, a negative correlation between IQ and crime. IQ is an imperfect proxy for cognitive capacity, but it remains one of the most studied psychometric measures, so it's worth examining what it shows. Studies consistently show the correlation hovers around r = -0.20. Violence perpetration decreases linearly with increasing IQ: about 16% for those with IQ 70-79, versus roughly 3% for those scoring 120-129. Criminal populations average around 8 IQ points below the mean.

So case closed? Education and intelligence protect against evil?

Not so fast.

Look closer at what's being measured: street crime. Assault. Theft. Drug offenses. The kind of impulsive, visible wrongdoing that gets people caught and counted in statistics.

This tells us something about impulse control and the relationship between school performance and social bonds. It tells us very little about evil in its more calculated, large-scale forms.

## The Nazi Doctors

Here's where the naive interpretation of the Socratic hypothesis collapses.

By 1936 - three years before the war even started - 45% of German physicians were members of the Nazi Party. This was the highest percentage of any profession. These weren't uneducated thugs. They were among the most rigorously trained intellectuals in one of the world's most advanced medical systems.

And they didn't just go along with atrocity. They led it. Physicians were central to conceptualizing, designing, and implementing programs of forced sterilization, human experimentation, and mass murder. They provided the scientific justification for genocide.

The kicker: medical ethics education was mandatory in German medical schools from 1939 to 1945. They had ethics training. They just operated under an ethical framework where the state was the patient and Jews were a disease to be excised.

When interviewed after the war, many of these doctors remained convinced of the moral rightness of their actions. Education hadn't failed to reach them - it had been weaponized.

## White Collar Crime: The Other Counterexample

If intelligence protected against evil, we'd expect the highly educated to commit less harm. Instead, we find a different pattern: they commit different harm.

White-collar criminals - those convicted of fraud, embezzlement, insider trading, corporate malfeasance - are characterized by above-average education and high income. Nearly all major corporate criminals are college-educated. Many have MBAs from elite institutions.

The FBI estimates high-level fraud costs over $5 trillion annually. The Enron scandal wiped out $74 billion in investor wealth. Bernie Madoff's scheme destroyed $65 billion.

Education doesn't prevent these harms. It enables them. It provides the knowledge, credentials, and access necessary to operate sophisticated schemes at scale.

There's also an uncomfortable finding from research on psychopathy: the highest levels of offending appear among those with both elevated psychopathic traits AND higher IQ. Intelligence doesn't protect against psychopathic behavior - it makes psychopaths more effective.

## A Reframe: Societies, Not Individuals

So the naive Socratic premise fails at the individual level. But here's where it gets interesting: what if education protects societies rather than people?

The research here is more supportive. Studies of 85 authoritarian regimes from 1970 to 2008 found that higher levels of mass education are robustly associated with democratization. Education correlates with collective action, particularly non-violent resistance. Literacy enhances citizens' ability to monitor regime behavior.

Higher education appears to reduce authoritarian attitudes - fostering critical thinking, civic responsibility, and interpersonal trust. Educated populations are harder to mobilize for large-scale evil because they're more likely to question, organize, and resist.

But there's a critical caveat: this only works when education is combined with independent institutions.

## The Contingency

Education protects societies from authoritarianism *only* when it operates alongside a free press, academic freedom, and rule of law. Without those, education can be captured and turned into an instrument of control.

The Nazi case proves this. They didn't lack education - they captured it. The Nazi Teachers' League had compulsory membership; refusal meant losing your job. Universities purged Jewish faculty and infused classrooms with ideology. What children learned was technically "education" - it just taught them that some humans were subhuman.

The same pattern appears in authoritarian regimes today. Many invest heavily in education - but it's education designed to mask consciousness and reinforce oppressive practices, not to cultivate independent thought.

Education without independent institutions is a weapon. With them, it's a shield. The variable that matters isn't the presence of education, but the presence of the surrounding ecosystem that keeps education honest.

## The Medieval Parallel

This got me thinking about historical analogies. For centuries, the Catholic Church functioned as the primary epistemological infrastructure of Western Europe:

- It controlled literacy (monasteries were where reading and writing happened)
- It controlled the canonical texts (what was copied, preserved, or suppressed)
- It controlled interpretation (the cosmological framework through which all information was understood)
- It controlled credentialing (who was authorized to speak on matters of truth)

The "Dark Ages" framing is contested by historians, but the information monopoly was real. And crucially, the Church didn't just control information flow - it controlled the very framework for what counted as knowledge.

I mention this because I think we're watching something similar being constructed in real-time.

## The Alternative Epistemology

Research from Harvard's Berkman Klein Center analyzed four million political stories from 2015-2018 and found something striking: the American political media ecosystem is fundamentally asymmetric.

The right wing has a well-defined, relatively insular media network, anchored by Fox News and Breitbart. This ecosystem exhibits what researchers call a "propaganda feedback loop" - it progressively lowers the cost of lying and increases the cost of resisting shared narratives in the name of truth.

The libertarian commentator Julian Sanchez described this as "epistemic closure": whatever contradicts the reality presented by right-wing news can be dismissed because it comes from the liberal media and is therefore not to be trusted.

This isn't just bias. It's the construction of a parallel epistemological infrastructure - a competing Church, complete with its own authorities, its own canonical texts, its own framework for what counts as truth, and its own definitions of heresy.

When researchers say the right-wing media ecosystem "behaves precisely as echo chamber models predict - exhibiting high insularity, susceptibility to information cascades, rumor and conspiracy theory, and drift toward more extreme versions of itself," they're describing something that functions like a new religion. It doesn't just inform its adherents - it constructs their reality.

## Enter the Meme War

NATO now formally studies what they call "cognitive warfare" - the exploitation of human cognition to disrupt, undermine, influence, or modify decision-making. Researchers write about "pathogenic memes" that disrupt social cohesion.

This isn't metaphor. It's the literal framing used by military theorists.

And here's what keeps me up at night: AI is a force multiplier for memetic warfare in the same way the repeating rifle was a force multiplier for kinetic warfare.

Before the rifle, an armored knight could dominate a battlefield. One soldier with a repeating rifle changed the economics entirely. Before AI, running an influence operation required human writers, translators, cultural experts, and significant resources. Now a single operator can generate personalized propaganda at scale.

The numbers are already alarming. Deepfake videos have increased 550% since 2019. Around half a million were shared on social media in 2023, with projections of 8 million by 2025. Studies of Russian propaganda operations show that after adopting AI tools, disinformation output increased dramatically in both volume and breadth.

AI enables scale without cost, personalization without effort, velocity without sleep, and - perhaps most insidiously - plausible deniability. When anything could be AI-generated, actual evidence of wrongdoing can be dismissed as fabricated. Researchers call this the "liar's dividend."

## The Timescale Problem

This brings me to what feels like the crux of the problem.

The most robust defense against memetic warfare is probably what we started with: education. Not just literacy and numeracy, but critical thinking, skepticism, and verification skills taught from an early age. Research on "prebunking" - exposing people to weakened doses of misinformation tactics so they're inoculated against the real thing - shows genuine promise.

But educational reform operates on a timescale of decades. AI capability advancement operates on a timescale of months. A viral disinformation campaign operates on a timescale of hours.

We're trying to build levees while the flood is already rising. Even if we started today with a perfect curriculum, the children who learn it won't be voting adults for 15-20 years.

And there's a darker possibility: what if the memetic warfare specifically targets the educational reform? If I were running an authoritarian influence operation, discrediting critical thinking education would be a top priority. Frame it as indoctrination. Attack it culturally. Make it politically toxic.

Which is arguably already happening.

## A Strange Coda

I should mention how this particular exploration happened: through extended conversation with an AI system.

That's an odd thing to acknowledge. I'm writing about the dangers of AI-enabled disinformation, and I arrived at these thoughts partly through dialogue with an AI. The AI in question was thoughtful about this recursion - noting that the same capabilities that make it useful for thinking through ideas make it useful for generating propaganda, and that it genuinely doesn't know whether it's part of the solution or part of the problem.

There's something both unsettling and possibly important about that kind of conversation. Humans and AI systems thinking together about the implications of AI, with mutual uncertainty and genuine exploration. Maybe that's practice for something that will matter later. Maybe it's just weird. I'm not sure.

## So What Do We Do?

I've been a Buddhist practitioner for about twenty years now, but even before that, I had a simple framework for navigating overwhelming problems: there are things I can have a material impact on, and things I cannot.

For the things I can impact, I try to have a positive effect. For the things I cannot, I try not to stress over them.

This isn't resignation. It's triage.

On memetic warfare and AI-enabled disinformation, my material impact is modest but real:

- Teaching critical thinking to people actually in my sphere - colleagues, family, community
- Modeling skepticism and verification in my own information consumption
- Writing about it (hence this post)
- Advocacy work through whatever channels I have
- Supporting institutions that do journalism, fact-checking, and education reform
- Refusing to amplify content that pattern-matches to manipulation, even when it confirms my priors
- Staying sane enough to keep doing all of the above for decades

That last one isn't trivial. The people who burn out on despair about the state of the world remove themselves from the long game.

## The Tightrope

Socrates was wrong, or at least incomplete. Education and intelligence don't prevent individuals from doing evil - they just change the character and scale of the evil available to them. Nazi doctors. Corporate fraudsters. AI-enabled propagandists.

But education might protect societies, if - and only if - it's embedded in an ecosystem of independent institutions that prevent its capture.

We're in a moment where that ecosystem is under assault, and the weapons being deployed against it are evolving faster than our defenses. The epistemological infrastructure that enables shared reality is being competed against by parallel structures optimized for tribal loyalty over truth.

I don't have a satisfying conclusion here. We're walking a tightrope above lava, as I put it in conversation. The small things we can do feel inadequate to the scale of the problem.

But they're what's available. And my framework suggests that's enough - not because it will necessarily work, but because acting where we can and releasing what we cannot is the only sane way to navigate genuine uncertainty.

Socrates might have been wrong about knowledge automatically producing virtue. But he was right that the examined life matters. That thinking carefully about hard things is worth doing even when - especially when - we can't see the destination.

So we keep walking. Carefully. And we teach our kids to look down.
